{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "\"\"\" Download all nltk packages through external ssl\"\"\"\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "example = ['Hi , How are you doing today?', 'You got a nice job at IBM.', 'Wow thats an awesome car.', 'Weather is great.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'down', \"should've\", 'not', 'how', \"shouldn't\", \"you'd\", 'any', 'he', 'this', 'for', 'shouldn', 'own', 'ours', 'because', 'him', 'herself', 'do', 'ain', \"hasn't\", 'off', 'were', \"hadn't\", 'have', \"weren't\", 'your', 'will', 'a', 'until', 'again', 'further', \"wouldn't\", 'it', 'having', 'had', 'can', 'what', \"haven't\", 'm', 'haven', 'after', 'her', 'than', 're', 'whom', 'yourselves', 'those', 'between', 'i', 'they', \"couldn't\", 'each', 'but', 'while', \"you've\", 'won', \"aren't\", 'under', \"mustn't\", 'doing', 'doesn', 'didn', 'his', \"needn't\", 'mustn', 'their', 'of', 'above', 'itself', 'the', 'where', 'wasn', 'more', 've', 'before', 'aren', \"it's\", \"you're\", 't', 'and', 'was', 'been', 'with', 'them', 'y', 'in', 'yours', 'd', 'or', 'through', 'is', \"that'll\", 'being', 'she', 'theirs', 'at', 'out', 'to', 'o', \"don't\", 'you', \"mightn't\", 'into', 'why', \"she's\", 'that', \"wasn't\", 'll', \"didn't\", 'only', 'don', 'such', 'all', 'too', 'if', 'most', 'who', 'same', 'by', 'does', 'mightn', 'should', 'an', 'hers', 'its', 'are', 'so', 'ma', 'myself', 'there', 'no', 'below', 'himself', 'when', 'here', 'me', 'hasn', \"shan't\", \"doesn't\", 'has', 'just', 's', 'now', 'did', 'during', 'some', 'ourselves', 'shan', 'couldn', 'as', 'hadn', 'my', 'we', 'both', \"isn't\", 'on', 'about', 'which', 'nor', 'from', 'other', 'needn', 'am', 'up', 'then', 'once', 'weren', 'these', 'against', 'be', \"won't\", 'our', \"you'll\", 'themselves', 'over', 'wouldn', 'few', 'yourself', 'isn'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'Mr.Pavan', ',', 'How', 'today', '?', '.', 'Cool', 'got', 'nice', 'job', 'IBM', '.', 'Wow', 'thats', 'awesome', 'car', '.', 'Weather', 'great', '.']\n"
     ]
    }
   ],
   "source": [
    "example_text = \"Hi Mr.Pavan , How are you doing today?. Cool you got a nice job at IBM. Wow thats an awesome car. Weather is great.\"\n",
    "words = word_tokenize(example_text)\n",
    "filtered_sentence = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john is an intellig individual.h intellig doe smart work .', 'he is a top perform in the compani .']\n"
     ]
    }
   ],
   "source": [
    "txt = \"John is an intelligent individual.He intelligently does smart work. He is a top performer in the company.\"\n",
    "sentences = sent_tokenize(txt)\n",
    "stemmer = PorterStemmer()\n",
    "new_sentence = []\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    new_sentence.append(' '.join(words))\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John is an intelligent individual.He intelligently doe smart work .', 'He is a top performer in the company .']\n"
     ]
    }
   ],
   "source": [
    "txt = \"John is an intelligent individual.He intelligently does smart work. He is a top performer in the company.\"\n",
    "sentences = sent_tokenize(txt)\n",
    "lemmtizer = WordNetLemmatizer()\n",
    "new__lemmatize_sentence = []\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [lemmtizer.lemmatize(word) for word in words]\n",
    "    new__lemmatize_sentence.append(' '.join(words))\n",
    "print(new__lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "# Now, let's create our training and testing data:\n",
    "train_txt=\"Crocodiles (subfamily Crocodylinae) or true crocodiles are large aquatic reptiles that live throughout the tropics in Africa, Asia, the Americas and Australia. Crocodylinae, all of whose members are considered true crocodiles, is classified as a biological subfamily. A broader sense of the term crocodile, Crocodylidae that includes Tomistoma, is not used in this article. The term crocodile here applies to only the species within the subfamily of Crocodylinae. The term is sometimes used even more loosely to include all extant members of the order Crocodilia, which includes the alligators and caimans (family Alligatoridae), the gharial and false gharial (family Gavialidae), and all other living and fossil Crocodylomorpha.\"\n",
    "sample_text =\"Crocodiles are large aquatic reptiles which are carnivorous.Allegators belong to this same reptile species\"\n",
    "# Next, we can train the Punkt tokenizer like:\n",
    "cust_tokenizer = PunktSentenceTokenizer(train_txt)\n",
    "# Then we can actually tokenize, using:\n",
    "tokenized = cust_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Tagging Output\n",
      "[('Crocodiles', 'NNS'), ('are', 'VBP'), ('large', 'JJ'), ('aquatic', 'JJ'), ('reptiles', 'NNS'), ('which', 'WDT'), ('are', 'VBP'), ('carnivorous.Allegators', 'NNS'), ('belong', 'RB'), ('to', 'TO'), ('this', 'DT'), ('same', 'JJ'), ('reptile', 'NN'), ('species', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Speech Tagging Output\")\n",
    "def process_text():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked Output\n",
      "(S\n",
      "  Crocodiles/NNS\n",
      "  are/VBP\n",
      "  (Chunk large/JJ aquatic/JJ)\n",
      "  reptiles/NNS\n",
      "  which/WDT\n",
      "  are/VBP\n",
      "  carnivorous.Allegators/NNS\n",
      "  belong/RB\n",
      "  to/TO\n",
      "  this/DT\n",
      "  (Chunk same/JJ)\n",
      "  reptile/NN\n",
      "  species/NNS)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# Now, let's create our training and testing data:\n",
    "train_txt=\"Crocodiles (subfamily Crocodylinae) or true crocodiles are large aquatic reptiles that live throughout the tropics in Africa, Asia, the Americas and Australia. Crocodylinae, all of whose members are considered true crocodiles, is classified as a biological subfamily. A broader sense of the term crocodile, Crocodylidae that includes Tomistoma, is not used in this article. The term crocodile here applies to only the species within the subfamily of Crocodylinae. The term is sometimes used even more loosely to include all extant members of the order Crocodilia, which includes the alligators and caimans (family Alligatoridae), the gharial and false gharial (family Gavialidae), and all other living and fossil Crocodylomorpha.\"\n",
    "sample_text =\"Crocodiles are large aquatic reptiles which are carnivorous.Allegators belong to this same reptile species\"\n",
    "\n",
    "# Next, we can train the Punkt tokenizer like:\n",
    "cust_tokenizer = PunktSentenceTokenizer(train_txt)\n",
    "\n",
    "# Then we can actually tokenize, using:\n",
    "\n",
    "tokenized = cust_tokenizer.tokenize(sample_text)\n",
    "print(\"Chunked Output\")\n",
    "def process_text():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk:{<NNS.?>*<JJ>+}\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            #chunked.draw()\n",
    "            print(chunked)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinked Output\n",
      "(S\n",
      "  (Chunk Crocodiles/NNS)\n",
      "  are/VBP\n",
      "  (Chunk large/JJ aquatic/JJ reptiles/NNS which/WDT)\n",
      "  are/VBP\n",
      "  (Chunk carnivorous.Allegators/NNS belong/RB)\n",
      "  to/TO\n",
      "  this/DT\n",
      "  (Chunk same/JJ reptile/NN species/NNS))\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# Now, let's create our training and testing data:\n",
    "train_txt=\"Crocodiles (subfamily Crocodylinae) or true crocodiles are large aquatic reptiles that live throughout the tropics in Africa, Asia, the Americas and Australia. Crocodylinae, all of whose members are considered true crocodiles, is classified as a biological subfamily. A broader sense of the term crocodile, Crocodylidae that includes Tomistoma, is not used in this article. The term crocodile here applies to only the species within the subfamily of Crocodylinae. The term is sometimes used even more loosely to include all extant members of the order Crocodilia, which includes the alligators and caimans (family Alligatoridae), the gharial and false gharial (family Gavialidae), and all other living and fossil Crocodylomorpha.\"\n",
    "sample_text =\"Crocodiles are large aquatic reptiles which are carnivorous.Allegators belong to this same reptile species\"\n",
    "\n",
    "# Next, we can train the Punkt tokenizer like:\n",
    "cust_tokenizer = PunktSentenceTokenizer(train_txt)\n",
    "\n",
    "# Then we can actually tokenize, using:\n",
    "\n",
    "tokenized = cust_tokenizer.tokenize(sample_text)\n",
    "\n",
    "print(\"Chinked Output\")\n",
    "def process_text():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            #chunked.draw()\n",
    "            print(chunked)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Output\n",
      "(S\n",
      "  Crocodiles/NNS\n",
      "  are/VBP\n",
      "  large/JJ\n",
      "  aquatic/JJ\n",
      "  reptiles/NNS\n",
      "  which/WDT\n",
      "  are/VBP\n",
      "  carnivorous.Allegators/NNS\n",
      "  belong/RB\n",
      "  to/TO\n",
      "  this/DT\n",
      "  same/JJ\n",
      "  reptile/NN\n",
      "  species/NNS)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# Now, let's create our training and testing data:\n",
    "train_txt=\"Crocodiles (subfamily Crocodylinae) or true crocodiles are large aquatic reptiles that live throughout the tropics in Africa, Asia, the Americas and Australia. Crocodylinae, all of whose members are considered true crocodiles, is classified as a biological subfamily. A broader sense of the term crocodile, Crocodylidae that includes Tomistoma, is not used in this article. The term crocodile here applies to only the species within the subfamily of Crocodylinae. The term is sometimes used even more loosely to include all extant members of the order Crocodilia, which includes the alligators and caimans (family Alligatoridae), the gharial and false gharial (family Gavialidae), and all other living and fossil Crocodylomorpha.\"\n",
    "sample_text =\"Crocodiles are large aquatic reptiles which are carnivorous.Allegators belong to this same reptile species\"\n",
    "\n",
    "# Next, we can train the Punkt tokenizer like:\n",
    "cust_tokenizer = PunktSentenceTokenizer(train_txt)\n",
    "\n",
    "# Then we can actually tokenize, using:\n",
    "\n",
    "tokenized = cust_tokenizer.tokenize(sample_text)\n",
    "\n",
    "print(\"Named Entity Output\")\n",
    "def process_text():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged,binary = True)\n",
    "            namedEnt.draw()\n",
    "            print(namedEnt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "process_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
